{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from hydroeval import nse, kge, pbias\n",
    "\n",
    "from fancyimpute import IterativeImputer as MICE\n",
    "from fancyimpute import NuclearNormMinimization, SoftImpute\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, SimpleRNN, Dense, Dropout, BatchNormalization, ConvLSTM2D, Bidirectional, Flatten\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras import backend\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_grdc(grdc_no):\n",
    "    data_date_month = []\n",
    "    data_date_common = []\n",
    "    data_value = []\n",
    "    f = open(\"final_asia/\" + grdc_no + \"_Q_Day.Cmd.txt\", \"rb\")\n",
    "    for i in f:\n",
    "        i = str(i)[2:-5]\n",
    "        if \"#\" in i:\n",
    "            continue\n",
    "        if \"YYYY\" in i:\n",
    "            continue\n",
    "        temp = [i.strip() for i in i.split(\";\")]\n",
    "        date_temp = temp[0].split(\"-\")\n",
    "        date_temp = [i.strip() for i in temp[0].split(\"-\")]\n",
    "        data_date_month.append(int(date_temp[1]))\n",
    "        data_date_common.append(date_temp[0] + \"-\" + date_temp[1] + \"-\" + date_temp[2])\n",
    "        data_value.append(round(float(temp[2]), 3))\n",
    "    df_temp = pd.DataFrame(list(zip(data_date_month, data_value, data_date_common)),\n",
    "                               columns =[\"Month\", \"Value\", \"Date\"])\n",
    "    df_temp = df_temp.set_index('Date')\n",
    "    df_temp = df_temp[df_temp[\"Month\"] != 0]\n",
    "    df_temp.sort_index()\n",
    "    df_index = df_temp.index\n",
    "    df_temp.replace(-999.0, np.nan, inplace=True)\n",
    "    \n",
    "    return df_temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(f):\n",
    "    \n",
    "    value = []\n",
    "    common = []\n",
    "    \n",
    "    grdc_no = \"\"\n",
    "    latitude = \"\"\n",
    "    longitude = \"\"\n",
    "    river = \"\"\n",
    "    \n",
    "    for i in f:\n",
    "        \n",
    "        i = str(i)[2:-5]\n",
    "        \n",
    "        if \"GRDC-No\" in i:\n",
    "            grdc_no = i.split(\":\")[1].strip()\n",
    "            continue\n",
    "        elif \"Latitude\" in i:\n",
    "            latitude = i.split(\":\")[1].strip()\n",
    "            continue\n",
    "        elif \"Longitude\" in i:\n",
    "            longitude = i.split(\":\")[1].strip()\n",
    "            continue\n",
    "        elif \"River\" in i:\n",
    "            river = i.split(\":\")[1].strip()\n",
    "            river = river.replace(',', '')\n",
    "            continue\n",
    "        elif \"YYYY\" in i:\n",
    "            continue\n",
    "        elif \"#\" in i:\n",
    "            continue\n",
    "\n",
    "        temp = [i.strip() for i in i.split(\";\")]\n",
    "        date_temp = temp[0].split(\"-\")\n",
    "        date_temp = [i.strip() for i in temp[0].split(\"-\")]\n",
    "        common.append(date_temp[0] + \"-\" + date_temp[1] + \"-\" + date_temp[2])\n",
    "        value.append(round(float(temp[2]), 3))\n",
    "        \n",
    "    return value, common, grdc_no, latitude, longitude, river"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merged(x, x_ncdc):\n",
    "    \n",
    "    x = x.set_index('Date')\n",
    "    x.sort_index()\n",
    "    x_ncdc = x_ncdc.set_index('DATE')\n",
    "    x_ncdc.sort_index()\n",
    "    \n",
    "    x_first = x.index[0] if x.index[0] > x_ncdc.index[0] else x_ncdc.index[0]\n",
    "    x_last = x.index[-1] if x.index[-1] < x_ncdc.index[-1] else x_ncdc.index[-1]\n",
    "    merged = pd.concat([x, x_ncdc], axis=1, sort=True)\n",
    "    to_delete = []\n",
    "    for i, r in merged.iterrows():\n",
    "        if i < x_first or i > x_last:\n",
    "            to_delete.append(i)\n",
    "            \n",
    "    merged = merged.drop(to_delete)\n",
    "    \n",
    "    return merged\n",
    "\n",
    "\n",
    "def merged2(x, x_ncdc):\n",
    "    x = x.set_index('Date')\n",
    "    x.sort_index()\n",
    "    x_ncdc = x_ncdc.set_index('DATE')\n",
    "    x_ncdc.sort_index()\n",
    "    merged = pd.concat([x, x_ncdc], axis=1, sort=True)\n",
    "    return merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = {}\n",
    "\n",
    "for filename in os.listdir(\"final_asia/\"):\n",
    "\n",
    "    f = open(\"final_asia/\" + filename, \"rb\")\n",
    "    f2 = pd.read_csv(\"NCDC/\" + filename[:7] + \".csv\")\n",
    "\n",
    "    value, common, grdc_no, latitude, longitude, river = get_data(f)\n",
    "    f.close()\n",
    "\n",
    "    df_temp = pd.DataFrame(list(zip(value, common)), columns =[\"Value\", \"Date\"])\n",
    "    df_temp = merged(df_temp, f2)\n",
    "    df2 = df_temp[\"Value\"]\n",
    "    df2 = df2.replace(-999.0, np.nan)\n",
    "    df2 = df2.fillna(df2.mean())\n",
    "    first_index = df_temp[\"LONGITUDE\"].first_valid_index()\n",
    "    temp_dict = {\n",
    "        \"GRDC_latitude\": latitude,\n",
    "        \"GRDC_longitude\": longitude,\n",
    "        \"NCDC_latitude\": df_temp[\"LATITUDE\"][first_index],\n",
    "        \"NCDC_longitude\": df_temp[\"LONGITUDE\"][first_index],\n",
    "        \"Elevation\": df_temp[\"ELEVATION\"][first_index],\n",
    "        \"River\": river\n",
    "    }\n",
    "    cols = list(df_temp.columns)\n",
    "    cols_to_keep = []\n",
    "    for i in cols:\n",
    "        if len(i) == 4 and i != \"NAME\" and i != \"SNWD\":\n",
    "            cols_to_keep.append(i)\n",
    "            cols.remove(i)\n",
    "    df_temp.drop(columns=cols, inplace=True)\n",
    "    df_temp.sort_index()\n",
    "    df_index = df_temp.index\n",
    "    soft_impute = SoftImpute(max_iters=300, verbose=False)\n",
    "    df_temp = soft_impute.fit_transform(df_temp)\n",
    "    df_temp = pd.DataFrame(data=df_temp, columns=cols_to_keep)\n",
    "    if \"PRCP\" in cols_to_keep:\n",
    "        df_temp[df_temp[\"PRCP\"] < 0] = 0\n",
    "    df_temp[\"Date\"] = df_index\n",
    "    df_temp = df_temp.set_index([\"Date\"])\n",
    "    df_temp[\"t-1\"] = df2.shift(1)\n",
    "    df_temp = df_temp.replace(np.nan, 0)\n",
    "    temp_dict[\"data_x\"] = df_temp\n",
    "    temp_dict[\"data_y\"] = df2\n",
    "    all_data[grdc_no] = temp_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_sequences(sequences, n_steps):\n",
    "\tX, y = list(), list()\n",
    "\tfor i in range(len(sequences)):\n",
    "\t\tend_ix = i + n_steps\n",
    "\t\tif end_ix > len(sequences)-1:\n",
    "\t\t\tbreak\n",
    "\t\tseq_x, seq_y = sequences[i:end_ix, :], sequences[end_ix, :]\n",
    "\t\tX.append(seq_x)\n",
    "\t\ty.append(seq_y)\n",
    "\treturn np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data_x2 = all_data[\"2998400\"][\"data_x\"]\n",
    "new_data_y = all_data[\"2998400\"][\"data_y\"]\n",
    "new_data_y2 = np.asarray(new_data_y).reshape((-1, 1))\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "new_data_x2 = scaler.fit_transform(new_data_x)\n",
    "new_data_y2 = scaler.fit_transform(new_data_y2)\n",
    "train_size = round(0.8*new_data_x2.shape[0])\n",
    "X_train = new_data_x2[:train_size]\n",
    "y_train = new_data_y2[:train_size]\n",
    "X_test = new_data_x2[train_size:]\n",
    "y_test = new_data_y2[train_size:]\n",
    "X_train2 = np.asarray(X_train).reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "y_train2 = np.asarray(y_train)\n",
    "X_test2 = np.asarray(X_test).reshape(X_test.shape[0], X_test.shape[1], 1)\n",
    "y_test2 = np.asarray(y_test)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(8, input_shape=[X_train2.shape[1], X_train2.shape[2]]))\n",
    "model.add(Dense(1))\n",
    "model.summary()\n",
    "model.compile(loss='mean_absolute_error', optimizer='adam', metrics=[tf.keras.metrics.RootMeanSquaredError()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train2, y_train2 ,epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_new = Sequential()\n",
    "model_new.add(LSTM(64, input_shape=[X_train2.shape[1], X_train2.shape[2]]))\n",
    "model_new.add(Dense(1))\n",
    "model_new.set_weights(model.get_weights())\n",
    "model_new.summary()\n",
    "model_new.compile(loss='mean_absolute_error', optimizer='adam', metrics=[tf.keras.metrics.RootMeanSquaredError()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tails = 5000\n",
    "heads = 90\n",
    "for i in all_data_test:\n",
    "    if i != \"2969200\":\n",
    "        continue\n",
    "    new_data_x = all_data_test[i][\"data_x\"]\n",
    "    new_data_y = all_data_test[i][\"data_y\"]\n",
    "    new_data_old = np.asarray(all_data[i][\"data_y\"].tail(tails))\n",
    "    new_data_x = new_data_x.loc[all_data[i][\"data_x\"].index[all_data[i][\"data_x\"].shape[0]-1]:]\n",
    "    new_data_y = new_data_y.loc[all_data[i][\"data_x\"].index[all_data[i][\"data_x\"].shape[0]-1]:]\n",
    "    x_axis = list(all_data[i][\"data_y\"].tail(tails).index) + list(new_data_x.index)\n",
    "    temp3 = len(x_axis)\n",
    "    temp2 = round(temp3/8)\n",
    "    x_labels = []\n",
    "    for j in range(0, temp3, temp2):\n",
    "        x_labels.append(x_axis[j])\n",
    "    if len(x_labels) < 9:\n",
    "        x_labels.append(x_axis[-1])\n",
    "\n",
    "    new_data_y2 = np.asarray(new_data_y).reshape((-1, 1))\n",
    "    initial = 0\n",
    "    new_data_x = np.asarray(new_data_x)\n",
    "    predictions_all = []\n",
    "    for i in new_data_x:\n",
    "        temp = np.append(i, initial)\n",
    "        temp = model_new.predict(temp.reshape(1,5,1))\n",
    "        initial = temp[0][0]\n",
    "        predictions_all.append(initial)\n",
    "        \n",
    "    results_train = predictions_all\n",
    "    plt.figure(figsize=(20,5))\n",
    "    plt.plot(range(len(new_data_old)), new_data_old, label=\"Actual\")\n",
    "    plt.plot(range(len(new_data_old), len(new_data_old) + len(results_train)), results_train, label=\"\")\n",
    "    plt.xticks(range(0,temp3, temp2), x_labels)\n",
    "    plt.legend(['Actual','Predicted'])\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.ylabel(\"Water Runoff\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit",
   "language": "python",
   "name": "python38264bitb12f8c46e2aa48e98c8cbe0a9fb1a934"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
